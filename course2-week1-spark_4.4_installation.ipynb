{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Apache installation"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#!wget https://download.java.net/java/GA/jdk13.0.1/cec27d702aa74d5a8630c65ae61e4305/9/GPL/openjdk-13.0.1_linux-x64_bin.tar.gz\n#!tar xvfz openjdk-13.0.1_linux-x64_bin.tar.gz\n!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n!pip install -q findspark\nimport os\n#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"SPARK_HOME\"] = \"/home/dsxuser/work/spark-2.4.4-bin-hadoop2.7\"\nimport findspark\nfindspark.init()\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SQLContext, SparkSession\nfrom pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, StringType\n#sc = SparkSession.builder.master(\"local[*]\").getOrCreate()\n#Spark Contexto\nsc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n\nsc",
            "execution_count": 2,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}